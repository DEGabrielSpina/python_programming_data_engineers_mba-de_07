ğŸ“ˆ Exchange Rate Data Pipeline

Este projeto implementa um pipeline ETL (Extract, Transform, Load) para capturar, tratar e armazenar cotaÃ§Ãµes de moedas obtidas via API de cÃ¢mbio.
As camadas de dados seguem a arquitetura raw â†’ silver â†’ gold, com persistÃªncia em banco de dados e em arquivos locais (formato parquet e json).

ğŸš€ Fluxo do Pipeline

Extrair

Arquivo: api_exchangerate.py

Conecta-se Ã  API de cÃ¢mbio (URL e chave no .env).

Retorna os dados em formato JSON.

Carregar na camada Raw

Arquivo: upload_on_repo.py

Salva o JSON em disco, dentro do diretÃ³rio configurado (dir_raw_path).

Transformar (camada Silver)

Arquivo: transfor_consist.py

Converte o JSON em DataFrame.

Remove registros nulos ou negativos.

Arquivo: upload_silver.py

Salva no banco (schema.table_silver) e em disco (dir_silver_path).

Enriquecer (camada Gold)

Arquivo: handle_rates.py

Calcula retorno percentual e volatilidade por moeda.

Arquivo: upload_gold.py

Persiste no banco (schema.table_gold) e em disco (dir_gold_path).

Consultar Silver

Arquivo: get_rates.py

Busca dados da camada silver via query definida no .env.

OrquestraÃ§Ã£o

Arquivo principal: main.py

Executa o pipeline completo.

Filtra apenas os dados da data atual.

Finaliza salvando a camada gold.

ğŸ›  Estrutura
.
â”œâ”€â”€ main.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api_exchangerate.py
â”‚   â”œâ”€â”€ CRUD.py
â”‚   â”œâ”€â”€ get_rates.py
â”‚   â”œâ”€â”€ handle_rates.py
â”‚   â”œâ”€â”€ log.py
â”‚   â”œâ”€â”€ transfor_consist.py
â”‚   â”œâ”€â”€ upload_gold.py
â”‚   â”œâ”€â”€ upload_on_repo.py
â”‚   â””â”€â”€ upload_silver.py

âš™ï¸ ConfiguraÃ§Ã£o

O projeto usa variÃ¡veis de ambiente em .env.
Crie um arquivo .env (ou .env.example no Git) com os seguintes parÃ¢metros:

# API
url=https://sua_api.com/exchangerate
api_key=SUA_CHAVE_API

# Banco
conn_url=postgresql://usuario:senha@host:porta/database
schema=nome_do_schema
table_silver=nome_tabela_silver
table_gold=nome_tabela_gold

# Queries
query_silver=SELECT * FROM schema.tabela_silver

# DiretÃ³rios locais
dir_raw_path=./data/raw
dir_silver_path=./data/silver
dir_gold_path=./data/gold

# Logs
log_path=./logs/app.log

â–¶ï¸ ExecuÃ§Ã£o

Para rodar o pipeline completo:

python main.py

ğŸ§© DependÃªncias

Python 3.9+

Bibliotecas:

pandas

sqlalchemy

python-dotenv

requests

streamlit (se for usar a interface interativa)

InstalaÃ§Ã£o:

pip install -r requirements.txt

ğŸ“ Logs

Implementados via log.py

Registram mensagens em arquivo definido por log_path no .env.

Exemplos: erros ao salvar no banco, problemas de conexÃ£o com API, avisos sobre dados invÃ¡lidos.

ğŸ“Š ExploraÃ§Ã£o de Dados com Streamlit

AlÃ©m do pipeline ETL, o projeto inclui um dashboard interativo em Streamlit para explorar a camada gold diretamente do banco (Neon/Postgres).

Arquivo: app.py
import streamlit as st
import pandas as pd
import os
from sqlalchemy import create_engine
from dotenv import load_dotenv

# Carregar variÃ¡veis do .env
load_dotenv()
conn_url = os.getenv("conn_url")
schema = os.getenv("schema")
table_gold = os.getenv("table_gold")

engine = create_engine(conn_url)

# Ler dados da camada gold
query = f"SELECT * FROM {schema}.{table_gold};"
df = pd.read_sql(query, con=engine)

st.title("ğŸ“Š ExploraÃ§Ã£o de CotaÃ§Ãµes - Camada Gold")

df["date"] = pd.to_datetime(df["date"])

# Filtro por moeda
moedas = df["coin"].unique()
moeda_escolhida = st.selectbox("Selecione a moeda", moedas)

df_filtrado = df[df["coin"] == moeda_escolhida]

st.subheader(f"Dados filtrados - {moeda_escolhida}")
st.dataframe(df_filtrado)

st.subheader("ğŸ“ˆ EvoluÃ§Ã£o da taxa de cÃ¢mbio")
st.line_chart(df_filtrado.set_index("date")["rate"])

st.subheader("ğŸ“ˆ Retorno percentual")
st.line_chart(df_filtrado.set_index("date")["return"])

st.subheader("ğŸ“‰ Volatilidade")
st.line_chart(df_filtrado.set_index("date")["volatility"])

ExecuÃ§Ã£o do dashboard
streamlit run app.py


Isso abrirÃ¡ a interface em http://localhost:8501, permitindo filtrar moedas, visualizar sÃ©ries histÃ³ricas, retornos e volatilidades.

ğŸ“Œ ObservaÃ§Ãµes

As tabelas silver e gold sÃ£o sobrescritas por data antes da inserÃ§Ã£o, garantindo consistÃªncia.

Linhas com valores nulos ou negativos em rate sÃ£o descartadas.

O projeto suporta tanto persistÃªncia em banco de dados quanto em arquivos parquet/json.

O Streamlit Ã© opcional, mas facilita a anÃ¡lise exploratÃ³ria e a apresentaÃ§Ã£o dos resultados.
